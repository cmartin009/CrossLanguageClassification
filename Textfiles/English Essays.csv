EN ESSAY
"There have been many studies in which researchers have attempted to classify student attentiveness. Many of these approaches depended on a qualitative analysis and lacked any quantitative analysis. Therefore, this work is focused on bridging the gap between qualitative and quantitative approaches to classify student attentiveness. Thus, this research applies machine learning algorithms (K-means and SVM) to automatically classify students as attentive or inattentive using data from a consumer RGB-D sensor. Results of this research can be used to improve teaching strategies for instructors at all levels and can aid instructors in implementing personalized learning systems, which is a National Academy of Engineering Grand Challenge. This research applies machine learning algorithms to an educational setting. Data from these algorithms can be used by instructors to provide valuable feedback on the effectiveness of their instructional strategies and pedagogies. Instructors can use this feedback to improve their instructional strategies, and students will benefit by achieving improved learning and subject mastery. Ultimately, this will result in the students' increased ability to do work in their respective areas. Broadly, this work can help advance efforts in many areas of education and instruction. It is expected that improving instructional strategies and implementing personalized learning will help create more competent, capable, and prepared persons available for the future workforce."
"Decision tree induction is one of the useful approaches for extracting classification knowledge from a set of feature-based instances. The most popular heuristic information used in the decision tree generation is the minimum entropy. This heuristic information has a serious disadvantage-the poor generalization capability [3]. Support vector machine (SVM) is a classification technique of machine learning based on statistical learning theory. It has good generalization. Considering the relationship between the classification margin of support vector machine(SVM) and the generalization capability, the large margin of SVM can be used as the heuristic information of decision tree, in order to improve its generalization capability. This paper proposes a decision tree induction algorithm based on large margin heuristic. Comparing with the binary decision tree using the minimum entropy as the heuristic information, the experiments show that the generalization capability has been improved by using the new heuristic."
"This paper firstly analyses the actual underwriting methods of Chinese life insurance companies, and points out the merits and shortcomings of these methods. Then the incomplete database of insurance company is mined by the data mining's association rule algorithm. Thirdly the support vector machine (SVM) is applied to the underwriting process to classify the applicants. Finally the directions for improving this algorithm are pointed out. The algorithm proposed in this paper has promising future in underwriting process."
"This paper presents a novel machine learning model-kernel granular support vector machine (KGSVM), which combines traditional support vector machine (SVM) with granular computing theory. By dividing granules and replacing with them in kernel space, the datasets can be reduced effectively without changing data distribution. And then the generalization performance and training efficiency of SVM can be improved. Simulation results on UCI datasets demonstrate that KGSVM is highly scalable for large datasets and very effective in terms of classification."
"Determination of model complexity is a challenging issue to solve computer vision problems using restricted boltzmann machines (RBMs). Many algorithms for feature learning depend on cross-validation or empirical methods to optimize the number of features. In this work, we propose an learning algorithm to find the optimal model complexity for the RBMs by incrementing the hidden layer. The proposed algorithm is composed of two processes: 1) determining incrementation necessity of neurons and 2) computing the number of additional features for the increment. Specifically, the proposed algorithm uses a normalized reconstruction error in order to determine incrementation necessity and prevent unnecessary increment for the number of features during training. Our experimental results demonstrated that the proposed algorithm converges to the optimal number of features in a single layer RBMs. In the classification results, our model could outperform the non-incremental RBM."
"Stock market or Share market is one of the most complicated and sophisticated way to do business. Small ownerships, brokerage corporations, banking sector, all depend on this very body to make revenue and divide risks; a very complicated model. However, this paper proposes to use machine learning algorithm to predict the future stock price for exchange by using open source libraries and preexisting algorithms to help make this unpredictable format of business a little more predictable. We shall see how this simple implementation will bring acceptable results. The outcome is completely based on numbers and assumes a lot of axioms that may or may not follow in the real world so as the time of prediction."
"We have investigated the risk factors that lead to severe retinopathy of prematurity using statistical analysis and logistic regression as a form of generalized additive model (GAM) with pairwise interaction terms (GA2M). In this process, we discuss the trade-off between accuracy and interpretability of these machine learning techniques on clinical data. We also confirm the intuition of expert neonatologists on a few risk factors, such as gender, that were previously deemed as clinically not significant in RoP prediction."
"This work proposes an intelligent learning diagnosis system that supports a Web-based thematic learning model, which aims to cultivate learners' ability of knowledge integration by giving the learners the opportunities to select the learning topics that they are interested, and gain knowledge on the specific topics by surfing on the Internet to search related learning courseware and discussing what they have learned with their colleagues. Based on the log files that record the learners' past online learning behavior, an intelligent diagnosis system is used to give appropriate learning guidance to assist the learners in improving their study behaviors and grade online class participation for the instructor. The achievement of the learners' final reports can also be predicted by the diagnosis system accurately. Our experimental results reveal that the proposed learning diagnosis system can efficiently help learners to expand their knowledge while surfing in cyberspace Web-based ""theme-based learning"" model."
"Semi-supervised support vector machine is an extension of standard support vector machine in machine learning problem in real life. However, the existing semi-supervised support vector machine algorithm has some drawbacks such as slower training speed, lower accuracy, etc. This paper presents a semi-supervised support vector machine learning algorithm based on active learning, which trains early learner by a spot of labeled-data, selects the best training samples for training and learning by active learning and reduces learning cost by deleting non- support vector. Simulative experiments have shown that the algorithm may get good learning effect at less learning cost."
"Transfer learning aims to improve a targeted learning task using other related auxiliary learning tasks and data. Most current transfer-learning methods focus on scenarios where the auxiliary and the target learning tasks are very similar: either (some of) the auxiliary data can be directly used as training examples for the target task or the auxiliary and the target data share the same representation. However, in many cases the connection between the auxiliary and the target tasks can be remote. Only a few features derived from the auxiliary data may be helpful for the target learning. We call such scenario the deep transfer-learning scenario and we introduce a novel transfer-learning method for deep transfer. Our method uses restricted Boltzmann machine to discover a set of hierarchical features from the auxiliary data. We then select from these features a subset that are helpful for the target learning, using a selection criterion based on the concept of kernel-target alignment. Finally, the target data are augmented with the selected features before training. Our experiment results show that this transfer method is effective. It can improve classification accuracy by up to more than 10%, even when the connection between the auxiliary and the target tasks is not apparent."
"IASS is the integrated anti-spam system, which adopts machine learning to filter spam in a intelligent, flexible, precise, and self-adaptive way. The methods of linear classification based on optimal separating hyperplane and K-means clustering are used in action recognition layer. The method of improved naive Bayes is used in content analysis layer. The application of machine learning helps improve the performance of IASS"
"Single machine scheduling methods have attracted a lot of attentions in recent years. Most dynamic single machine scheduling problems in practice have been addressed using dispatching rules. However, no single dispatching rule has been found to perform well for all important criteria, and no rule takes into account the status or the other resources of system's environment. In this research, an intelligent agent-based single machine scheduling system is proposed, where the agent is trained by a new improved Q-learning algorithm. In such scheduling system, agent selects one of appropriate dispatching rules for machine based on available information. The agent was trained by a new simulated annealing-based Q-learning algorithm. The simulation results show that the simulated annealing-based Q-learning agent is able to learn to select the best dispatching rule for different system objectives. The results also indicate that simulated annealing-based Q-learning agent could perform well for all criteria, which is impossible when using only one dispatching rule independently."
"The objective of this work is to present a machine learning (ML) -based framework to identify evidence about collaborative problem solving (CPS) cognitive (teamwork) and social-emotional learning (SEL) skills from the dyadic (human-human-HH) interactions. This work extends our previous work (Chopade et al. IEEE HST 2018, LAK2019) [1], [2]. Explicitly, we are interested in how teamwork skills and team dynamics are demonstrated as verbal and nonverbal behaviors, and how these behaviors can be captured and analyzed via passive data collection. For this work we use a two-player cooperative CPS game, Crisis in Space (CIS) from LRNG (Previously GlassLab Inc). During the summer of 2018, we implemented this CIS game for interns as a group study. A total of 34 participants played the game and provided study and survey data. During the study, we collected participants' game play data, such as audio, video and eye tracking data streams. This research involves analyzing CIS multimodal game data, and developing skill models, and machine learning techniques for CPS skills measurement. In this paper, we present our ML framework for the analysis of audio data along with preliminary results from a pilot study. The analysis of audio data uses natural language processing (NLP) techniques, such as bag-of-words and sentence embedding. Our preliminary results show that various NLP features can be used to describe successful and unsuccessful CPS performances. The ML based framework supports the development of evidence centered design for teamwork skills-mapping and aims to help teams operate effectively in a complex situation. Potential applications of this work include support for the Department of Homeland Security (DHS), and the US Army for the development of learner and team centric training, cohort, and team behavioral skill-mapping."
"Representation learning is the base and crucial for consequential tasks, such as classification, regression, and recognition. The goal of representation learning is to automatically learning good features with deep models. Multimodal representation learning is a special representation learning, which automatically learns good features from multiple modalities, and these modalities are not independent, there are correlations and associations among modalities. Furthermore, multimodal data are usually heterogeneous. Due to the characteristics, multimodal representation learning poses many difficulties: how to combine multimodal data from heterogeneous sources; how to jointly learning features from multimodal data; how to effectively describe the correlations and associations, etc. These difficulties triggered great interest of researchers along with the upsurge of deep learning, many deep multimodal learning methods have been proposed by different researchers. In this paper, we present an overview of deep multimodal learning, especially the approaches proposed within the last decades. We provide potential readers with advances, trends and challenges, which can be very helpful to researchers in the field of machine, especially for the ones engaging in the study of multimodal deep machine learning."
"This study investigates the use of tree-based machine learning methods in concrete non-destructive tests (NDT) evaluation. The study encompassed different phases. The first involved the use of destructive and non-destructive mechanisms to assess concrete strength on cube specimens. The second phase examined site assessment of selected structures using popular NDT tools. The third phase implemented a tree-based machine learning approach to characterize a relationship between concrete properties and destructive compressive strength for cubes and selected structures. It established that ultrasonic speed and rebound number were adequate to predict compressive strength. Variable importance plots from boosted tree learning suggested a hierarchy of parameter importance that challenges Pearson's correlation coefficients. In order to establish the effectiveness of tree-methods, analyses show that classical regression struggled to attain a variance score of 0.43 during training while boosted tree doubled this score during testing on unseen validation set. The results present a case for tree-based analysis in concrete NDT evaluation."
"Today, social networks have been part of many people's lives. Many activities such as communication, promotion, advertisement, news, agenda creation have started to be done through social networks. Some malicious accounts on Twitter are used for purposes such as misinformation and agenda creation. This is one of the basic problems in social networks. Therefore, detection of malicious account is significant. In this study, machine learning-based methods were used to detect fake accounts that could mislead people. For this purpose, the dataset generated was pre-processed and fake accounts were determined by machine learning algorithms. Decision trees, logistic regression and support vector machines algorithms are used for the detection of fake accounts. Classification performances of these methods are compared and the logistic regression proved to be more successful than the others."
"The theory of machine learning in metric space is a new research topic and has drawn much attention in recent years. The theoretical foundation of this topic is the question under which conditions two sample sets can be separated in this space. In this paper, motivated by developing a new support vector machine (SVM) in fuzzy number space, we present a necessary and sufficient condition of separating two finite classes of samples by a hyper-plane in n-dimensional fuzzy number space. We also present an attainable expression of maximal margin of the separating hyper-planes which includes some cases of the classes of infinite samples in n-dimensional fuzzy number space. These results generalize and improve the corresponding conclusions for the theory of SVM in Hilbert space to fuzzy number space."
"The traditional SVM does not support incremental learning. And the traditional training method of SVM is not working when the amount of training samples are so large that they can not be put into the RAM of computer. In order to solve this problem and improve the speed of training SVM, the natural characteristics of SV are analyzed in this paper. An incremental learning algorithm (I-SVM) for SVM with discarding part of history samples is presented. The theoretical analysis and experimental results show that this algorithm can not only speed up the training process, but also reduce the storage cost, while the classification precision is also guaranteed."
"This paper presents an exploratory machine learning attack based on deep learning to infer the functionality of an arbitrary classifier by polling it as a black box, and using returned labels to build a functionally equivalent machine. Typically, it is costly and time consuming to build a classifier, because this requires collecting training data (e.g., through crowdsourcing), selecting a suitable machine learning algorithm (through extensive tests and using domain-specific knowledge), and optimizing the underlying hyperparameters (applying a good understanding of the classifier's structure). In addition, all this information is typically proprietary and should be protected. With the proposed black-box attack approach, an adversary can use deep learning to reliably infer the necessary information by using labels previously obtained from the classifier under attack, and build a functionally equivalent machine learning classifier without knowing the type, structure or underlying parameters of the original classifier. Results for a text classification application demonstrate that deep learning can infer Naive Bayes and SVM classifiers with high accuracy and steal their functionalities. This new attack paradigm with deep learning introduces additional security challenges for online machine learning algorithms and raises the need for novel mitigation strategies to counteract the high fidelity inference capability of deep learning."
"We present two input data preprocessing methods for machine learning (ML). The first one consists in extending the set of attributes describing objects in input data table by new attributes and the second one consists in replacing the attributes by new attributes. The methods utilize formal concept analysis (FCA) and boolean factor analysis, recently described by FCA, in that the new attributes are defined by so-called factor concepts computed from input data table. The methods are demonstrated on decision tree induction. The experimental evaluation and comparison of performance of decision trees induced from original and preprocessed input data is performed with standard decision tree induction algorithms ID3 and C4.5 on several benchmark datasets."
In this paper we discuss various machine learning approaches used in mining of data. Further we distinguish between symbolic and sub-symbolic data mining methods. We also attempt to propose a hybrid method with the combination of Artificial Neural Network (ANN) and Cased Based Reasoning (CBR) in mining of data.
"Due to the complexity and flexibility of natural language, automatic linguistic knowledge acquisition and its application research becomes difficult. In this paper, we present a machine learning method to automatically acquire Chinese linguistic ontology knowledge from typical corpus. This study, first, defined the description frame of Chinese linguistic ontology knowledge, and then, automatically acquired the usage of a Chinese word with its co-occurrence of context in using semantic, pragmatics, syntactic, etc from the corpus, final, the above information and their representation act as Chinese linguistic ontology knowledge bank. We completed two groups of experiments, i.e. documents similarity computing, text reordering for information retrieval. Compared with previous works, the proposed method solves the inferior precision of nature language processing."
"Summary form only given. Learning is becoming the central problem in trying to understand intelligence and in trying to develop intelligent machines. The paper outlines some previous efforts in developing machines that learn. It sketches the authors's work on statistical learning theory and theoretical results on the problem of classification and function approximation that connect regularization theory and support vector machines. The main application focus is classification (and regression) in various domains-such as sound, text, video and bioinformatics. In particular, the paper describe the evolution of a trainable object detection system for classifying objects-such as faces and people and cars-in complex cluttered images. Finally, it speculates on the implications of this research for how the brain works and review some data which provide a glimpse of how 3D objects are represented in the visual cortex."
"In this paper, we use a deep learning method, restricted Boltzmann machine, for nonlinear system identification. The neural model has deep architecture and is generated by a random search method. The initial weights of this deep neural model are obtained from the restricted Boltzmann machines. To identify nonlinear systems, we propose special unsupervised learning methods with input data. The normal supervised learning is used to train the weights with the output data. The modified algorithm is validated by modeling two benchmark systems."
"Based on statistical learning theory (SLT), support vector machine (SVM), which is a new kind of machine learning method that is used for classification and regression. SVM is considered as two layers learning machine since it maps the original space into a high dimensional feature space, i.e., input layer and high dimensional feature space layer. If the high dimensional feature space layer is considered as a new problem's input layer and the new problem is also solved by SVM, the new problem can be solved by SVMs named multi-layer SVM (MLSVM). MLSVM is composed of input layer and at least one layer high dimensional feature space layer. In this paper, m-th order ordinary differential equations are solved by MLSVM for regression. Experimental results indicate that MLSVM can effectively solve the problem of ordinary differential equations. Thus, MLSVM exhibits its great potential to solve other complex problems"
"The support vector machines are the new statistical learning algorithm which is developed in recent years. They have some advantages in many regions like pattern recognition. The kernel function is important to its classification ability. This paper presents a crossbreed genetic algorithm based method to choose the kernel function and its parameters. The crossbreed genetic algorithm uses two fitness functions which are produced according to the two criterion of SVM's performance. The experiments proved that this algorithm can find effectively the optimal kernel function and its parameters, and it is helpful to increase the support vector machines' performance in fact."
"The importance of vocational and technical training is growing day by day in parallel to the developing technology. It is inevitable to utilise opportunities presented by information and communication technologies in order to determine vocational fields in vocational and technical training in the most efficient manner. In this respect, it is possible to create a more efficient tool compared to the current methods by utilising machine learning which is an artificial intelligence model in energy applications that predicts events in the future depending on the past experiences. In the current study, a software is developed that ensures that the system learns about the successful and unsuccessful choices made in the past by applying “Naive Bayes” algorithm, which is a machine learning algorithm, to the data collected concerning the individuals who turned out to be successful or unsuccessful in the vocational technical training process in energy applications. In the software developed, it is aimed that the system recommends the most suitable vocational field for the individual by according to the data collected from the individual who is in the occupation selection process in field energy applications."
"Support vector machine (SVM) is novel type learning machine, based on statistical learning theory, which tasks involving classification, regression or novelty detection. This paper investigates an inverse problem of support vector machines (SVMs). The inverse problem is how to split a given dataset into two clusters such that the margin between the two clusters attains the maximum. Here the margin is defined according to the separating hyper-plane generated by support vectors. It is difficult to give an exact solution to this problem. In this paper, we design a genetic algorithm to solve this problem. Numerical simulations show the feasibility and effectiveness of this algorithm. This study on the inverse problem of SVMs is motivated by designing a heuristic algorithm for generating decision trees with high generalization capability."
"Support vector machine (SVM) has become a popular tool of pattern recognition in recent years for its outstanding learning performance. When dealing with large-scale learning problems, incremental SVM framework is generally used because SVM can summarize the data space in a concise way. This paper proposes a training algorithm of incremental SVM with recombining method. Considering the differences of data distribution and the impact of new training data on history data, the history training dataset and the new training one are divided into independent groups and are recombined to train a classifier. In fact, this method can be implemented in a parallel structure for the actions of dividing may decrease the computation complexity of training a SVM. Meanwhile, the actions of recombining may weaken the potential impact caused by the difference of data distribution. The experiment results on a text dataset show that this training algorithm is effective and the classification accuracy of proposed incremental algorithm is superior to that using batch SVM model."
"A new method of early fault diagnosis for manufacturing system based on machine learning is presented. It is necessary for manufacturing enterprises to detect the states of production process in real time, in order to find the early faults in machines, so that the losses of production failure and investments of facility maintenance can be minimized. This paper proposes a new fault diagnosis model, which extracts multi-dimension features from the detected signal to supervise the different features of the signal simultaneously. Based on the model, the method of inductive learning is adopted to obtain the statistical boundary vectors of the signal automatically, and then a normal feature space is built, according to which an abnormal signal can be detected, and consequently the faults in a complicated system can be found easily. Furthermore, under the condition of without existing fault samples, the precise results of fault diagnosis can also be achieved in real time. The theoretical analysis and simulation example demonstrate the effectiveness of the method."
"Cyber bullying is the use of technology as a medium to bully someone. Although it has been an issue for many years, the recognition of its impact on young people has recently increased. Social networking sites provide a fertile medium for bullies, and teens and young adults who use these sites are vulnerable to attacks. Through machine learning, we can detect language patterns used by bullies and their victims, and develop rules to automatically detect cyber bullying content. The data we used for our project was collected from the website Formspring.me, a question-and-answer formatted website that contains a high percentage of bullying content. The data was labeled using a web service, Amazon's Mechanical Turk. We used the labeled data, in conjunction with machine learning techniques provided by the Weka tool kit, to train a computer to recognize bullying content. Both a C4.5 decision tree learner and an instance-based learner were able to identify the true positives with 78.5% accuracy."
"A novel real-time acoustic feedback (RTAF) based on machine learning to reduce the duration and to improve the progress in the rehabilitation is presented. Wearable technology (WT) has emerged as a viable means to provide low-cost digital healthcare and therapy course outside the medical environment like hospitals and clinics. In this paper we show that the RTAF together with WTs can offer an excellent solution to be used in rehabilitation. The method of RTAF based on machine learning as well as a study for proving its effectiveness are presented below. The results show a faster recovery time using RTAF. The proposed RTAF shows a great potential to be used and deployed to support digital healthcare, therapy and rehabilitation."
"In this paper, we present a framework which enables medical decision making in the presence of partial information. At its core is ontology-based automated reasoning, machine learning techniques are integrated to enhance existing patient datasets in order to address the issue of missing data. Our approach supports interoperability between different health information systems. This is clarified in a sample implementation that combines three separate datasets (patient data, drug-drug interactions and drug prescription rules) to demonstrate the effectiveness of our algorithms in producing effective medical decisions. In short, we demonstrate the potential for machine learning to support a task where there is a critical need from medical professionals by coping with missing or noisy patient data and enabling the use of multiple medical datasets."
"There are 700,000 Rheumatoid Arthritis (RA) patients in Japan, and the number of patients is increased by 30,000 annually. The early detection and appropriate treatment according to the progression of RA are effective to improve the patient's prognosis. The modified Total Sharp (mTS) score is widely used for the progression evaluation of Rheumatoid Arthritis. The mTS score assessments on hand or foot X-ray image is required several times a year, and it takes very long time. The automatic mTS score calculation system is required. This paper proposes the finger joint detection method and the mTS score estimation method using support vector machine. Experimental results on 45 RA patient's X-ray images showed that the proposed method detects finger joints with accuracy of 81.4 %, and estimated the erosion and JSN score with accuracy of 50.9, 64.3 %, respectively."
"A common problem when trying to apply data mining techniques to improve educational systems is the disconnection between those who have the expertise (e.g. Universities) and those who have access to the data (e.g. Small companies). Bringing expertise into educational in-production systems is complicated because companies are reluctant to invest a lot of effort into integrating new technology that they do not fully trust, while the technology cannot prove its worth without access to real, valid data. In this paper we explore the requirements that machine learning systems have to be applied to specific learning problems (sequencing and performance prediction), and then propose a minimally invasive protocol for sequencing (based on web services) to easily integrate Learning Analytics Services into e-learning systems."
"Web filtering based on user's demand has witnessed a booming interest due to the development of Internet In the research community the dominant approach to this problem is based on machine learning algorithms. Web filtering is an inductive process which automatically builds a filter by learning from a set of pre-assigned document and the description of user's interest, and then uses it to assign unfiltered Web pages. This survey compares four main machine learning algorithms (decision tree, rule induction, Bayesian algorithm and support vector machines) on Chinese web pages set of their filtering effectiveness and computer resources consumed, focusing on the influence of feature set size and training set size. It induces that support vector machines earn high score in Chinese Web filtering applications."
"Timing closure is essential in SoC physical design. In this paper, machine learning models for timing prediction after floorplan are established. In the models, the features are selected and abstracted by analyzing these parameters from gate-level netlist, constraint files, and floorplan files. The classic machine learning algorithms, such as neural network, support vector machine (SVM), and ensemble machine learning, are explored. The corresponding regression models are applied to predict the timing of SoC. The testcase constructed by open source IP core is used to verify the proposed idea. The results show that the hybrid ensemble learning model has the best prediction performance among various learning models evaluated in this paper."
"This paper addresses the recent trends in machine learning methods for the automatic classification of remote sensing (RS) images. In particular, we focus on two new paradigms: semisupervised and active learning. These two paradigms allow one to address classification problems in the critical conditions where the available labeled training samples are limited. These operational conditions are very usual in RS problems, due to the high cost and time associated with the collection of labeled samples. Semisupervised and active learning techniques allow one to enrich the initial training set information and to improve classification accuracy by exploiting unlabeled samples or requiring additional labeling phases from the user, respectively. The two aforementioned strategies are theoretically and experimentally analyzed considering SVM-based techniques in order to highlight advantages and disadvantages of both strategies."
"In order to examine malicious activity that occurs in a network or a system, intrusion detection system is used. Intrusion Detection is software or a device that scans a system or a network for a distrustful activity. Due to the growing connectivity between computers, intrusion detection becomes vital to perform network security. Various machine learning techniques and statistical methodologies have been used to build different types of Intrusion Detection Systems to protect the networks. Performance of an Intrusion Detection is mainly depends on accuracy. Accuracy for Intrusion detection must be enhanced to reduce false alarms and to increase the detection rate. In order to improve the performance, different techniques have been used in recent works. Analyzing huge network traffic data is the main work of intrusion detection system. A well-organized classification methodology is required to overcome this issue. This issue is taken in proposed approach. Machine learning techniques like Support Vector Machine (SVM) and Naïve Bayes are applied. These techniques are well-known to solve the classification problems. For evaluation of intrusion detection system, NSL- KDD knowledge discovery Dataset is taken. The outcomes show that SVM works better than Naïve Bayes. To perform comparative analysis, effective classification methods like Support Vector Machine and Naive Bayes are taken, their accuracy and misclassification rate get calculated."
"In the past years, mobile devices were limited to textual content. However, the current generation has started to access richer multimedia content such as video, increasing the diversity of devices accessing the Web. Then, a problem arises as some of those devices characteristics like memory capacity or screen resolution turn the access to a content restricted. The present work considers the use of machine learning techniques as part of a dynamic video adaptation process, comparing the results from two of the most used approaches for data analysis, Multilayer Perceptron and Bayesian Inference, as part of a Decision Engine, analyzing data like device's capabilities, user's preferences and network condition in order to take the most appropriate way to adapt a video stream."
"In practice, there are many imbalanced data classification problems, for example, spam filtering, credit card fraud detection and software defect prediction etc. it is important in theory as well as in application for investigating the problem of imbalanced data classification. In order to deal with this problem, based on extreme learning machine autoencoder, this paper proposed an approach for addressing the problem of binary imbalanced data classification. The proposed method includes 3 steps. (1) the positive instances are used as seeds, new samples are generated for increasing the number of positive instances by extreme learning machine autoencoder, the generated new samples are similar with the positive instances but not same. (2) step (1) is repeated several times, and a balanced data set is obtained. (3) a classifier is trained with the balanced data set and used to classify unseen samples. The experimental results demonstrate that the proposed approach is feasible and effective."
"Manufacturing industry is facing major challenges to meet customer requirements, which are constantly changing. Therefore, products have to be manufactured with efficient processes, minimal interruptions, and low resource consumptions. To achieve this goal, huge amounts of data generated by industrial equipment needs to be managed and analyzed by modern technologies. Since the big data era in manufacturing industry is still at an early stage, there is a need for a reference architecture that incorporates big data and machine learning technologies and aligns with the Industrie 4.0 standards and requirements. In this paper, requirements for designing a scalable analytics platform for industrial data are derived from Industrie 4.0 standards and literature. Based on these requirements, a reference big data architecture for industrial machine learning applications is proposed and compared to related works. Finally, the proposed architecture has been implemented in the Lab Big Data at the SmartFactoryOWL and its scalability and performance have been evaluated on parallel computation of an industrial PCA model. The results show that the proposed architecture is linearly scalable and adaptable to machine learning use cases and will help to improve the industrial automation processes in production systems."
"Compromising wavelet kernel and multi-class least squares support vector machines, this article put forward to a fault diagnosis model based on multi-class wavelet support vector machine. The model heightens auto-adaptive model classification ability by adjustment of scale parameter of wavelet kernel, and make use of remarkable learning ability and generalization ability of small sample of vector machines to improve speed and effectiveness of fault diagnosis. And taking fault diagnosis in heat-recycling system of thermal power plant as an example to analysis."
"The Euclidean distance is usually chosen as the similarity measure in the conventional similarity metrics, which usually relates to all attributes. The smaller the distance is, the greater the similarity is. All the features of each vector have different functions in describing samples. So we can decide on the different functions of every feature by using feature weight learning, that is, introduce feature weight parameters to the distance formula. Feature weight learning can be viewed as a linear transformation for a set of points in the Euclidean space. The numerical experiments applied in K-means clustering prove the validity of this learning algorithm."
"This thesis elaborated the concept, significance and main strategy of machine learning as well as the basic structure of machine learning system. By combining several basic ideas of main strategies, great effort are laid on introducing several machine learning methods, such as Rote learning, Explanation-based learning, Learning from instruction, Learning by deduction, Learning by analogy and Inductive learning, etc. Meanwhile, comparison and analysis are made upon their respective advantages and limitations. At the end of the article, it proposes the research objective of machine learning and points out its development trend.Machine learning is a fundamental way that enable the computer to have the intelligence ; Its application which had been used mainly the method of induction and the synthesis, rather than the deduction has already reached many fields of Artificial Intelligence."
"As the expansion of the standard Support Vector Machine, compared with the traditional standard Support Vector Machine, the Least Squares Support Vector Machine loses the sparseness of standard Support Vector Machine, which would affect the efficiency of the second study. Aimed at the above puzzle, the article proposed an improved Least Squares Support Vector Machine incremental learning method, using self-adaptive methods to prune the sample, according to the performance of the classifier which each training has been to set the pruning threshold and the increment size of the sample. If you get a good performance of classifier, pruning threshold and sample increment is big, the other hand, if you get a poor performance of classifier, pruning threshold and sample increment is small, resulting in improved efficiency of Least Squares Support Vector Machine training to solve the sparse problem. The simulation experiment results verify the proposed algorithm is feasible."
"The Machine Type Communication Devices (MTCDs) are usually based on Internet Protocol (IP), which can cause billions of connected objects to be part of the Internet. The enormous amount of data coming from these devices are quite heterogeneous in nature, which can lead to security issues, such as injection attacks, ballot stuffing, and bad mouthing. Consequently, this work considers machine learning trust evaluation as an effective and accurate option for solving the issues associate with security threats. In this paper, a comparative analysis is carried out with five different machine learning approaches: Naive Bayes (NB), Decision Tree (DT), Linear and Radial Support Vector Machine (SVM), KNearest Neighbor (KNN), and Random Forest (RF). As a critical element of the research, the recommendations consider different Machine-to-Machine (M2M) communication nodes with regard to their ability to identify malicious and honest information. To validate the performances of these models, two trust computation measures were used: Receiver Operating Characteristics (ROCs), Precision and Recall. The malicious data was formulated in Matlab. A scenario was created where 50% of the information were modified to be malicious. The malicious nodes were varied in the ranges of 10%, 20%, 30%, 40%, and the results were carefully analyzed."
"Machine Translation(MT) is a part of Natural Language Processing(NLP). It is the method of translating Source Language(SL) text into Target Language(TL). The gap between computer programmer and linguist can be resolved with this system. The problems like lexical ambiguity, part of speech tagging, syntactic and structural ambiguity, synonym etc will arise while developing such systems. To develop a proper bilingual machine translation system for two natural languages is a challenging and demanding task for researchers. It is required to analyze the information as well as technology behind every natural language translation. This work represents the various approaches with current trends of machine translation system. In recent trends various machine learning approaches have been developed to tackle the above said problems. Most recently neural machine translation attain very good result by using different deep neural network techniques and machine learning algorithms."
"1960s civil rights and racial justice activists tried to warn us about our technological ways, but we didn't hear them talk. The so-called wizards who stayed up late ignored or dismissed black voices, calling out from street corners to pulpits, union halls to the corridors of Congress. Instead, the men who took the first giant leaps towards conceiving and building our earliest ""thinking"" and ""learning"" machines aligned themselves with industry, government and their elite science and engineering institutions. Together, they conspired to make those fighting for racial justice the problem that their new computing machines would be designed to solve. And solve that problem they did, through color-coded, automated, and algorithmically-driven indignities and inumahities that thrive to this day. But what if yesterday's technological elite had listened to those Other voices? What if they had let them into their conversations, their classrooms, their labs, boardrooms and government task forces to help determine what new tools to build, how to build them and - most importantly - how to deploy them? What might our world look like today if the advocates for racial justice had been given the chance to frame the day's most preeminent technological question for the world and ask, ""Computerize the Race Problem?"" Better yet, what might our AI-driven future look like if we ask ourselves this question today?"
"Computer mice have their displacement sensors in various locations (center, front, and rear). However, there has been little research into the effects of sensor position or on engineering approaches to exploit it. This paper first discusses the mechanisms via which sensor position affects mouse movement and reports the results from a study of a pointing task in which the sensor position was systematically varied. Placing the sensor in the center turned out to be the best compromise: improvements over front and rear were in the 11-14% range for throughput and 20--23% for path deviation. However, users varied in their personal optima. Accordingly, variable-sensor-position mice are then presented, with a demonstration that high accuracy can be achieved with two static optical sensors. A virtual sensor model is described that allows software-side repositioning of the sensor. Individual-specific calibration should yield an added 4% improvement in throughput over the default center position."
"Teaching parallel and distributed computing (PDC) concepts is an ongoing and pressing concern for many undergraduate educators. The ACM/IEEE CS Joint Task Force on Computing Curricula (CS2013) recommends 15 hours of PDC education in the undergraduate curriculum. Most recently, the 2019 ABET Criteria for Accrediting Computer Science requires coverage of PDC topics. For faculty who are unfamiliar with PDC, the prospect of incorporating parallel computing into their courses can seem very daunting. For example, should PDC concepts be covered in a single required course (perhaps computer systems) or be scattered throughout different courses in the undergraduate curriculum? What languages are the best/easiest for students to learn PDC? How much revision is truly needed? This Birds of a Feather session provides a platform for computing educators to discuss the common challenges they face when attempting to incorporate PDC into their curricula and share potential solutions. Chiefly, the organizers are interested in identifying ""gap areas"" that hinder a faculty member's ability to integrate PDC into their undergraduate courses. The multiple viewpoints and expertise provided by the BOF leaders should lead to lively discourse and enable experienced faculty to share their strategies with those beginning to add PDC across their curricula. We anticipate that this session will be of interest to all CS faculty looking to integrate PDC into their courses and curricula."
"Computing Education Research (CER) implicitly assumes that CS undergraduate students have no barrier to access a learning platform or software package. The assumption that ""everyone has access to and uses a device"" endangers the validity of CER studies by overlooking a critical element in what students access and how students use computing resources. First, in this work, we explicitly investigate undergraduate student usage (how often) of computing resources (laptops and computer labs) on a university campus. Furthermore, we investigate whether CS student usage of laptops and computer labs are factors of success in computing education to close a crucial feedback loop for CER and CS educators. Second, previous studies studying student's technology equipped used qualitative surveys, and lacked a systematic and continuous view of the student population. In this work, we address this shortcoming by developing a method to use operational data sets from the wireless networks and computer labs on campus. Operational data sets provide a systematic and continuous coverage of all students, that is, a student's absence of usage becomes a data point instead of a missing point. Results indicate that the use of equipment levels may be lower than national average. Nevertheless, there exists a positive correlation between higher frequency of laptop usage and success in computing education."
"The purpose of this study were to 1) study the current problem, requirement and condition of learning environment of computer teaching, 2)develop a model of creativity based learning for computer teaching, 3) evaluate the results of using a model of creativity based learning, and 4) assess the learning achievement from using creativity based learning model. The respondents of this study are 59 undergraduate students from computer program. The research instruments include course syllabus, pretest and posttest questionnaire, and paper test of creativity design based on four parts of rubric scale. Data were analyzed by descriptive statistical mean, standard deviation, and t-test. The results found that 59 sample agreed with a model of creativity-based learning, and the students were able to learn better when creativity -based learning apply with information media and technology, creativity and innovation and collaboration, teamwork and leadership. The learning achievement from using creativity -based learning was higher than pre-test at the 0.05 level of significance. The students were satisfied with using creativity-based learning to show the ideas of creating and learning by themselves."
"This paper expands on knowledge of computing identity by building on what is known about prior identity models in science and mathematics education. The model theorizes three primary sub-constructs that contribute to the development of a computing identity: belief in one's performance/competence, interest, and recognition in computing. Drawing on data from a nationally representative survey of more than 1,700 college students at 22 colleges and universities, the study tested the alignment of the theorized model to the measures on the survey. Confirmatory Factor Analysis was used to validate whether the appropriate measures loaded on the three separate sub-constructs. Criterion-related validity was also established by testing whether the computing identity measures predicted the choice of a computer science career. The results reveal that a computing identity proxy based on the theorized measures was a highly significant predictor of students' computer science and information technology career choice (p < 0.0001). In addition, this work also established criterion-related validity by showing gender differences that had been found by prior work in computing. Finally, the theorized measures were found to be reliable and internally consistent. The educational understanding of computing identities may provide an important tool to help researchers and practitioners improve student persistence in computer science."
"We report on a curricular experiment at Stanford University focused on teaching computer ethics. After nearly a year of preparation, we launched a new course at the intersection of ethics, public policy, and technology that deeply marries the humanities, social sciences, and computer science. While the teaching of computer ethics courses dates back decades, such courses are often taught by a (single) CS faculty member without significant training in ethics, do not include a policy component, and are meant for CS students. By contrast, we take a deeply multidisciplinary approach, where three faculty instructors, from philosophy, political science, and CS, each bring their respective lens to four related course modules: algorithmic decision-making, data privacy and civil liberties, AI and autonomous systems, and the power of platform companies. Panels of guest speakers drawn from academia, industry, civil society, and government provide a practitioner's view of the topics addressed. Additionally, custom case studies were developed under the direction of the course staff. These materials (videos of the speaker panels and the case studies) are freely available for use by the broader community. We report on the details of the course structure, including how multiple disciplines are integrated throughout the course, including lectures, discussions, and assignments. We discuss aspects of the course that worked well as well as challenges in making the course broadly accessible (beyond just CS majors). Importantly, we also include a discussion of students' response to the course, showing that a deeply multidisciplinary approach resonates strongly with them."
"As the digital economy grows, so does the demand for technology-capable workers who have both computing skills and domain expertise. Growing such a workforce is critical to ensuring the nation's competitiveness, according to a recent National Science Board publication. To address this need, faculty from the Colleges of Engineering and Social Sciences at San Jóse State University worked together to create the Applied Computing for Behavioral and Social Sciences minor degree. The minor targets students in majors such as Psychology and Economics, which have a more diverse student population than that of Computer Science or Engineering. The minor, designed with industry input, includes a four-course sequence that focuses on Python and R and includes topics such as data structures, algorithms, data cleaning and management, and data analysis. Our cohort-based program was built specifically for social science students using social science content, helping to foster a sense of community and belongingness among students. The first full cohort of 26 students graduated in Spring 2019, 48% of whom were female and 23% of whom were underrepresented minorities. Our approach of embedding computing education into the social sciences demonstrates a promising model of broadening participation in computing and meeting the nation's increasing demand for interdisciplinary computing workers in the digital age."
"Advances in nanosatellite technology and a declining cost of access to space have fostered an emergence of large constellations of sensor-equipped satellites in low-Earth orbit. Many of these satellite systems operate under a ""bent-pipe"" architecture, in which ground stations send commands to orbit and satellites reply with raw data. In this work, we observe that a bent-pipe architecture for Earth-observing satellites breaks down as constellation population increases. Communication is limited by the physical configuration and constraints of the system over time, such as ground station location, nanosatellite antenna size, and energy harvested on orbit. We show quantitatively that nanosatellite constellation capabilities are determined by physical system constraints."
"A Lifetime Service award suggests many years of being involved in Computer Science Education. Over these years I have gained numerous active caring insights to promote support and guide Computer Science Educators. Being a successful CS educator does not just involve gaining a qualification and teaching classes. There are so many exciting and rewarding aspects to this career that enhance the classroom experience for all and also add to the promotion and excitement of the discipline. These insights are gathered from over 40 years of teaching and supervising students, 25 years as a Chair of Department and some exciting and innovative research projects. From the villages in the high Andes to local diversity issues, from coding in binary and hex to apps on smart phones the revolution of the digital age has been a major part of my journey in computer science education."
"What can be Computed is a textbook for a course that covers Decidable Languages, Computable Functions, Recursively Enumerable Languages, Turing Machines, Reductions, Regular Languages, P, NP, and NPcompleteness. Since there are already many books with these topics in them, the question is:"
"Contemporary computing devices contain a concoction of numerous hazardous materials. Though users are more or less protected from these substances, recycling and landfilling reintroduce them to the biosphere where they may be ingested by people. This paper calls on HCI researchers to consider these corporal interactions with computers and critiques HCI's existing responses to the e-waste problem. We propose that whether one would consider eating a particular electronic component offers a surprisingly useful heuristic for whether we ought to be producing it on mass with vanishingly short lifespans. We hypothesize that the adoption of this heuristic might affect user behaviour and present a diet plan for users who wish to take responsibility for their own e-waste by eating it. Finally we propose an alternative direction for HCI researchers to design and advocate for those affected by the material properties of e-waste."
"In this column, we introduce our Model AI Assignment, A Module on Ethical Thinking about Autonomous Vehicles in an AI Course, and more broadly introduce a conversation on ethics education in AI education."
"Humans and AI systems are usually portrayed as separate systems that we need to align in values and goals. However, there is a great deal of AI technology found in non-autonomous systems that are used as cognitive tools by humans. Under the extended mind thesis, the functional contributions of these tools become as essential to our cognition as our brains. But AI can take cognitive extension towards totally new capabilities, posing new philosophical, ethical and technical challenges. To analyse these challenges better, we define and place AI extenders in a continuum between fully-externalized systems, loosely coupled with humans, and fully internalized processes, with operations ultimately performed by the brain, making the tool redundant. We dissect the landscape of cognitive capabilities that can foreseeably be extended by AI and examine their ethical implications.We suggest that cognitive extenders using AI be treated as distinct from other cognitive enhancers by all relevant stakeholders, including developers, policy makers, and human users."
"When we think about the values AI should have in order to make right decisions and avoid wrong ones, there's a large but hidden third category to consider: decisions that are not-wrong but also not-right. This is the grey space of judgment calls, and just having good values might not help as much as you'd think here. I'll use autonomous cars as my case study here, with lessons for broader AI: ethical dilemmas can arise in everyday scenarios such as lane positioning and navigation, not just in crazy crash scenarios. This is the space where one good value might conflict with another good value, and there's no ""right"" answer or even broad consensus on an answer; so, it's important to recognize the hard cases-which are potential limits-in the study of AI ethics."
"The ability of an AI agent to build mental models can open up pathways for manipulating and exploiting the human in the hopes of achieving some greater good. In fact, such behavior does not necessarily require any malicious intent but can rather be borne out of cooperative scenarios. It is also beyond the scope of misinterpretation of intents, as in the case of value alignment problems, and thus can be effectively engineered if desired (i.e. algorithms exist that can optimize such behavior not because models were misspecified but because they were misused). Such techniques pose several unresolved ethical and moral questions with regards to the design of autonomy. In this paper, we illustrate some of these issues in a teaming scenario and investigate how they are perceived by participants in a thought experiment. Finally, we end with a discussion on the moral implications of such behavior from the perspective of the doctor-patient relationship."
"It has become commonplace to assert that autonomous agents will have to be built to follow human rules of behavior--social norms and laws. But human laws and norms are complex and culturally varied systems; in many cases agents will have to learn the rules. This requires autonomous agents to have models of how human rule systems work so that they can make reliable predictions about rules. In this paper we contribute to the building of such models by analyzing an overlooked distinction between important rules and what we call silly rules -- rules with no discernible direct impact on welfare. We show that silly rules render a normative system both more robust and more adaptable in response to shocks to perceived stability. They make normativity more legible for humans, and can increase legibility for AI systems as well. For AI systems to integrate into human normative systems, we suggest, it may be important for them to have models that include representations of silly rules."
"My dissertation asks two fundamental questions: What are the risks of AI? And what should be done about them? My research goes beyond existential threats to humanity to consider seven dimensions of AI risk: military, political, economic, social, environmental, psychophysiological, and spiritual. I examine extant AI risk mitigation strategies and, finding them insufficient, use a democratic governance framework to propose alternatives. This paper outlines the project and introduces the risk dimensions."
"Open-access AI educational resources are vital to the quality of the AI education we offer. Avoiding the reinvention of wheels is especially important to us because of the special challenges of AI Education. AI could be said to be ""the really interesting miscellaneous pile of Computer Science"". While ""artificial"" is well-understood to encompass engineered artifacts, ""intelligence"" could be said to encompass any sufficiently difficult problem as would require an intelligent approach and yet does not fall neatly into established Computer Science subdisciplines. Thus AI consists of so many diverse topics that we would be hard- pressed to individually create quality learning experiences for each topic from scratch."
"We present an innovative methodology for studying and teaching the impacts of AI through a role-play game. The game serves two primary purposes: 1) training AI developers and AI policy professionals to reflect on and prepare for future social and ethical challenges related to AI and 2) exploring possible futures involving AI technology development, deployment, social impacts, and governance. While the game currently focuses on the inter-relations between short-, mid- and long-term impacts of AI, it has potential to be adapted for a broad range of scenarios, exploring in greater depths issues of AI policy research and affording training within organizations."
"Over the past few years, specialised online and offline press blossomed with articles about art made ""with"" Artificial Intelligence (AI) but the narrative is rapidly changing. In fact, in October 2018, the auction house Christie's sold an art piece allegedly made ""by"" an AI. We draw from philosophy of art and science arguing that AI as a technical object is always intertwined with human nature despite its level of autonomy. However, the use of creative autonomous agents has cultural and social implications in the way we experience art as creators as well as audience. Therefore, we highlight the importance of an interdisciplinary dialogue by promoting a culture of transparency of the technology used, awareness of the meaning of technology in our society and the value of creativity in our lives."
"Artificial Intelligence and robotics are rapidly moving into healthcare, playing key roles in specific medical functions, including diagnosis and clinical treatment. Much of the focus in the technology development has been on human-machine interactions, leading to a host of related technology-centric questions. In this paper, we focus instead on the impact of these technologies on human-human interactions and relationships within the healthcare domain. In particular, we argue that trust plays a central role for relationships in the healthcare domain, and the introduction of healthcare AI can potentially have significant impacts on those relations of trust."
"There has been a growing awareness of Artificial Intelligence's (AI) inherent biases, limitations, and the challenges in overcoming them. As AI is integrated into to all things technical, there is a valid concern over its diversity, inclusiveness, and accessibility. However, questions such as what does it mean for AI to be inclusive, why is inclusive AI required, and how can it be achieved, largely remain unanswered. In this paper, we highlight these issues to initiate discussions on what it means for AI to be inclusive."
"Since its codified genesis in the 18th century, ballet training has largely been unchanged: it relies on the word of mouth expertise passed down generation to generation and in tools that do not adequately support both dancers and teachers. Moreover, top-tier training is only found in a few locations around the world and comes at an exceptional price. In this context, artificial intelligence (AI)-based video tools might represent an affordable and non-invasive alternative: it would allow dancers and teachers to self-assess as well as enable skilled dance teachers to connect with a wider audience. In my research, I study how to design and evaluate AI-based tools to improve ballet performance for dancers and teachers."
"Implicit in any rhetorical interaction-between humans or between humans and machines-are ethical codes that shape the rhetorical context, the social situation in which communication happens and also the engine that drives communicative interaction. Such implicit codes are usually invisible to AI writing systems because the social factors shaping communication (the why and how of language, not the what) are not usually explicitly evident in databases the systems use to produce discourse. Can AI writing systems learn to learn rhetorical context, particularly the implicit codes for communication ethics? We see evidence that some systems do address issues of rhetorical context, at least in rudimentary ways."
"New technologies, particularly those which are deployed rapidly across sectors, or which have to operate in competitive conditions, can disrupt previously stable technology governance regimes. This leads to a precarious need to balance caution against performance while exploring the resulting 'safe operating space'. This paper will argue that Artificial Intelligence is one such critical technology, the responsible deployment of which is likely to prove especially complex, because even narrow AI applications often involve networked (tightly coupled, opaque) systems operating in complex or competitive environments. This ensures such systems are prone to 'normal accident'-type failures which can cascade rapidly, and are hard to contain or even detect in time."
"Estimation, planning, control, and learning are giving us robots that can generate good behavior given a specified objective and set of constraints. What I care about is how humans enter this behavior generation picture, and study two complementary challenges: 1) how to optimize behavior when the robot is not acting in isolation, but needs to coordinate or collaborate with people; and 2) what to optimize in order to get the behavior we want. My work has traditionally focused on the former, but more recently I have been casting the latter as a human-robot collaboration problem as well (where the human is the end-user, or even the robotics engineer building the system)."
"Artificial Intelligence (AI) ethics is by no means a new discipline; thinkers like Asimov and Philip K Dick laid the foundations of this field decades ago. Both then and today, popular dilemmas in AI ethics largely focus on artificial consciousness, artificial general intelligence, autonomous weapons, and some version of the trolley problem. While these thought experiments may prove useful in the future, modern AI applications that are in use today raise ethical dilemmas that require urgent resolution. Public outcry in response to AI in health care, criminal justice, and employment highlight the urgency of the matter. These real and imminent ethical challenges posed by AI form the basis of my dissertation research. In particular, I focus on domains where AI is necessary or inevitable -- such as kidney exchange and medical image classification -- and ethical challenges are unavoidable."
"The last few years have seen a huge growth in the capabilities and applications of Artificial Intelligence (AI) and autonomous systems. Hardly a day goes by without news about technological advances and the societal impact of the use of AI. AI is changing the way we work, live and solve challenges. For example, it can improve healthcare, protect elephants from poachers, and work out how broadband should be distributed."
"Certainty around the regulatory environment is crucial to facilitate responsible AI innovation and its social acceptance. However, the existing legal liability system is inapt to assign responsibility where a potentially harmful conduct and/or the harm itself are unforeseeable, yet some instantiations of AI and/or the harms they may trigger are not foreseeable in the legal sense. The unpredictability of how courts would handle such cases makes the risks involved in the investment and use of AI incalculable, creating an environment that is not conducive to innovation and may deprive society of some benefits AI could provide. To tackle this problem, we propose to draw insights from financial regulatory best-practices and establish a system of AI guarantee schemes."
"Artificial intelligence and machine learning (AI/ML) are some of the newest trends to hit the software industry, compelling organizations to evolve their development processes to deliver novel products to their customers. In this talk, I describe a study in which we learned how Microsoft software teams develop AI/ML-based applications using a nine-stage AI workflow process informed by prior experiences developing early AI applications (e.g. search and NLP) and data science tools (e.g. application telemetry and bug reporting). Adapting this workflow into their pre-existing, well-evolved, Agile-like software engineering processes and job roles has resulted in a number of engineering challenges unique to the AI/ML domain, some universal to all teams, but others related to the amount of prior AI/ML experience and education the teams have. I tell you about some challenges and the solutions that teams have come up with. The lessons that Microsoft has learned can help other organizations embarking on their own path towards AI and ML."
"Remotely Unattended Installation / Uninstallation of Software is a collection of tools that allow the network administrator, sitting at his or her desk, to manage a network of remote PCs and accomplish the tasks like, support of daily IT operations and management task; whether your job is deploying software, Installation of softwares, collecting information from remote computers. These tasks include the installation of new applications and updates, remote control or monitoring of network workstations, keeping an inventory of software and hardware installed on those systems, and many other functions that will be described in detail throughout the manual. Administrator can send installable files of software to the number of client PC if client PCs requested that software. Administrator can get all the information of client PCs to its terminal like hardware configuration, software configuration, memory status, port status of client PCs."
"Software needs to grow up and become responsible for itself and its own future by participating in its own installation and customization, maintaining its own health, and adapting itself to new circumstances, new users, and new uses. To create such software will require us to change some of our underlying assumptions about how we write programs. A promising approach seems to be to separate software that does the work (allopoietic)from software that keeps the system alive (autopoietic)."
"In lots of software projects unfortunately an architectural erosion happens over time. Modules which were independent, become connected, plug-ins finally depend on each other, and in general the architecture gets violated more and more. In this paper we will discuss how to avoid such architecture- and design-erosion and how an already eroded system can be fixed again. We will look at three different level of static analysis and examine architectural analysis in detail. Also typical use cases for architectural analysis are examined, followed by a collection of requirements for powerful tool support. The eclipse platform serves as case study and we look if, and how far architectural erosion happened there and if it can be fixed. Finally we discuss pros and cons of architectural analysis and conclude with an out view."
"This paper deals with the problem of reliability in a hardware/software system. More specifically it deals with the strategy used to achieve reliability in a particular hardware/software system built by the author and his colleagues at Carnegie-Mellon University. Rather than dealing with the myriad details of the reliability aspects of this systems, the paper focuses on the design philosophy which aims at keeping the system operational even though the underlying hardware may be malfunctioning. This philosophy is essentially an extension of the 'modular' programming methodology, advocated by Parnas and others, to include dynamic error detection and recovery."
"Every discipline, e.g. medicine and engineering, has its own vocabulary to describe situations and tools. This dedicated language is important, because it allows for being specific, detailed and precise. On the other hand, this language, specific to each discipline, becomes a barrier for communication across disciplines. International software measurement standards are examples of such language. The standards are documents that provide definitions of terms used and describe processes specific to the discipline of software measurement. However, one major problem we have observed is that standards are difficult to read and to understand; even for the stakeholders that they are intended for."
"Agile methodology uses the incremental and iterative method and is commonly utilized in the Pakistan's industry projects as they can accommodate changes in requirements. Product distribution is accomplished by using small iterations/repetitions, but guaranteeing the quality of the product is important and crucial part as well as it is a tough task. Quality should be assured of the product that is developed using agile methodology. The study centers on the five key parts of software testing, explicitly software testing methods, software testing metrics, practices and techniques, testing standards, automated testing tools, and testing education & training. Grounded on survey outcomes, research paper evaluates the implementation of existing practices in the software testing, provide some recommendations and observations for the software testing future in Pakistan IT industry & also suggested the solution that how quality is assured in agile software development using different factors."
"No two flight missions are alike, hence, development and on-orbit software costs are high. Software portability and adaptability across hardware platforms and operating systems has been minimal at best. Standard interfaces across applications and/or common applications are almost non-existent. To reduce flight software costs, these issues must be addressed. This presentation describes how the Flight Software Branch at Goddard Space Flight Center has architected a solution to these problems."
"JaamSim is a free, open-source simulation package written in the Java programming language. It is a general-purpose dynamic simulator that supports discrete-event logic, continuous variables, and agent-based model design. A modern graphical user interface is provided that is comparable to commercial software, including drag-and-drop model building, an Input Editor, Output Viewer, and 3D graphics. Users are able to create their own palettes of high-level objects using standard Java and modern programming tools such as Eclipse. If you are writing hundreds or thousands of lines of code in a proprietary programming language provided with your commercial software, you would be far better off to write your code in Java and use JaamSim."
"This study addresses the problem of cost estimation in the context of software evolution by building a set of quantitative models and assessing their predictive power. The models aim at capturing the relationship between effort, productivity and a suite of metrics of software evolution extracted from empirical data sets."
"The Software Test Program (STP) is a cooperation between Motorola and the Center for Informatics of the Federal University of Pernambuco. It has been conceived with inspiration on the Medical Residency, adjusted to the software development practice. A Software Residency includes the formal teaching of the relevant concepts and deep practice, with specialization on some specific subject; here the focus is on software testing. The STP has been of great benefit to all parties involved."
"Software Engineering courses are essential for undergraduates to achieve a smooth transition from higher education to a career. However, many of these courses encounter complications that forbid them from meeting their goals such as: Real products and customers, project duration, software sophistication and more. At Chico State, we have implemented the Tech Startup Model in which the Software Engineering students partner with entrepreneurship students to allow for more collaboration and the creation of a customer-employee relation to address some of these issues. This model utilizes both Lean Startup as well as Agile Development to continuously test a student's ability to adapt to the customer's needs. The data accumulated from the past couple of semesters allowed us to analyze student behavior when exposed to the Tech Startup Model as opposed to other methods tested from previous semesters."
"Mining software engineering data has emerged as a successful research direction over the past decade. In this position paper, we advocate Software Intelligence (SI) as the future of mining software engineering data, within modern software engineering research, practice, and education. We coin the name SI as an inspiration from the Business Intelligence (BI) field, which offers concepts and techniques to improve business decision making by using fact-based support systems. Similarly, SI offers software practitioners (not just developers) up-to-date and pertinent information to support their daily decision-making processes. SI should support decision-making processes throughout the lifetime of a software system not just during its development phase."
"Despite its importance, Software Quality Engineering is longing to make its way into software lifecycle standards. This article analyses the recently published ISO/IEC 24748 systems and software lifecycle management guide against other standards and academic material, and proposes additions to make to the standard for it to properly promote and support software quality engineering."
"The global, local and firm economies depend on software in an ever increasing way. Writing effective software on a day to day basis, for a long time (decades, maybe) depends upon agility (as a process and timing) to have, as consequences, reliability, scalability and security, in times of software and systems as services.

The only way to achieve such tense and, in most cases, opposite goals, is to try and find business models (for software ops) that are continuously searching for a repeatable, scalable business models."
"This paper describes a demonstration of the product line engineering tool and framework Gears from BigLever software. Gears provides a single feature modeling language, a single variation point mechanism, and a single automated product configurator that are used to configure a product portfolio's shared engineering assets appropriately for each product in the portfolio. The result is an automated production line capability that can quickly produce any product in the portfolio from the same, single set of shared assets."
"Software Studio is a studio-based learning (SBL) curriculum designed to train students as professional software engineers. Traditional software engineering courses remain important, but suffer significant gaps in preparing students for professional engagement. We describe our curriculum model, highlight ways in which it fills these gaps, and offer a SWOT analysis. As practical guidance, we reflect on our missteps and successes in implementing Software Studio over the past five semesters. Finally, we suggest future directions for Software Studio"
"Despite its importance, Software Quality Engineering is longing to make its way into software lifecycle standards. This article analyses the recently published ISO/IEC 24748 systems and software lifecycle management guide against other standards and academic material, and proposes additions to make to the standard for it to properly promote and support software quality engineering."
"The global, local and firm economies depend on software in an ever increasing way. Writing effective software on a day to day basis, for a long time (decades, maybe) depends upon agility (as a process and timing) to have, as consequences, reliability, scalability and security, in times of software and systems as services."
"Engineering research differs greatly, both in its aims and in its methods, from traditional ""scientific"" research. While Sciences deal with the study of existing objects and phenomena, be it physically, metaphysically or conceptually, Engineering is based on how to do things, how to create new objects. For this reason, ""scientific"" research methods are not always directly applicable to research problems of an engineering nature.In the present article, we concentrate on the problems and research methods of a specific branch of engineering: Software Engineering, discussing, on the one hand, the nature of the method in this field while and, on the other, the similarity of the methods of research in Software Engineering and those of software development."
"Software Studio is a studio-based learning (SBL) curriculum designed to train students as professional software engineers. Traditional software engineering courses remain important, but suffer significant gaps in preparing students for professional engagement. We describe our curriculum model, highlight ways in which it fills these gaps, and offer a SWOT analysis. As practical guidance, we reflect on our missteps and successes in implementing Software Studio over the past five semesters. Finally, we suggest future directions for Software Studio."